# Environment Configuration

# NVIDIA API Key (Required)
# Get your key from: https://build.nvidia.com/
NVIDIA_API_KEY=your_nvidia_api_key_here

# Service Ports (Optional - defaults shown)
ORCHESTRATOR_PORT=8000
WEATHER_PORT=8001
MAPS_PORT=8002
NEWS_PORT=8003
SOCIAL_PORT=8004
RESOURCE_PORT=8005

# Logging Configuration
LOG_LEVEL=INFO

# LLM Configuration (Two-Stage Architecture)
# ============================================
# BALANCED CONFIGURATION (Recommended)
# Total response time: ~6-12 seconds
# ============================================

# Stage 1: Fast Decision Model (Small, Quick Triage)
# Purpose: Quickly determine if situation is emergency or false alarm
# Expected time: ~1-2 seconds
DECISION_MODEL=nvidia/llama-3.2-nv-embedqa-1b-v2

# Stage 2: Response Model (Large, Detailed Output)
# Purpose: Generate detailed assessment or evacuation plan
# Expected time: ~5-10 seconds
RESPONSE_MODEL=meta/llama-3.1-70b-instruct

# Alternative Configurations:
# ============================================
# SPEED PRIORITY (~4-6 seconds total):
#   DECISION_MODEL=nvidia/llama-3.2-1b-instruct
#   RESPONSE_MODEL=meta/llama-3.1-8b-instruct
#
# ACCURACY PRIORITY (~15-25 seconds total):
#   DECISION_MODEL=nvidia/nemotron-mini-4b-instruct
#   RESPONSE_MODEL=meta/llama-3.1-405b-instruct
# ============================================

# LLM Parameters
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=2000

# Application Settings
APP_NAME=CrisisVision Backend
DEBUG=False
